{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yavuzuzun/projects/blob/main/Lab2_ECE442.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This notebook is a Homework prepared for thr ECE 442 Network Science Analytics class taught by Gonzalo Mateos during Spring 2023\n",
        "## Descriptive analysis of network graph characteristics\n",
        "In this second laboratory we will re-examine some of the structural properties of large-scale networks we discussed in class (for instance, power-law degree distributions and assortative mixing). In particular, we will corroborrate that these properties indeed arise with some real-world networks encountered across diverse domains. Moreover, we will implement a few of the classic spectral-based algorithms for graph partitioning or network community detection. Various metrics to assess performance of these unsupervised node clustering algorithms will be introduced, which we will bring to bear in our experiments with the workhorse Zachary's Karate Club network and a political blog graph from the 2004 US presidential election."
      ],
      "metadata": {
        "id": "r_70W1d-wTg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load graspologic. This is a library that will be quite helpful in the following\n",
        "# laboratory on Models for network graphs and their applications. For now, we will\n",
        "# just leverage one of the useful methods it provides.\n",
        "# before that we load prior versions of scipy, networkx and gensim because those\n",
        "# that come with Colab are not compatible with graspologic (this will be fixed soon)\n",
        "!pip install --upgrade scipy\n",
        "!pip install networkx==2.8.5\n",
        "!pip install gensim==4.2.0\n",
        "!pip install psutil==5.9.4\n",
        "!pip install graspologic==2.0.0"
      ],
      "metadata": {
        "id": "6XZQjKwVh-0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import PyTorch\n",
        "import torch"
      ],
      "metadata": {
        "id": "uhm7zOFEwhNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install PyG for the working version of PyTorch\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install torch-geometric"
      ],
      "metadata": {
        "id": "2c9aotr_wkgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##IMPORTANT: Restart runtime\n",
        "After installing the libraries in the cells above, you must restart Colab's runtime (go to Runtime --> Restart runtime or Ctrl+M). Otherwise, you will an error in the cell that follows. "
      ],
      "metadata": {
        "id": "JPs6vdyY55J4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the libraries we will use\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "# load that specific method from graspologic I want to use later on\n",
        "from graspologic.utils import remap_labels"
      ],
      "metadata": {
        "id": "di83Ec6nR9EV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Structural properties of large-scale networks"
      ],
      "metadata": {
        "id": "Bpdq4JmxL4HU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Degree distribution\n",
        "In this section we will examine the degree distribtion of a real network, constructed from citation data among machine learning papers. Given an undirected graph $G$, let $P(d)$ denote the fraction of vertices in the graph with degree $d$. The collection $\\{P(d)\\}_{d\\geq 0}$ is the *degree distribution of graph $G$*. For example, in the toy graph depicted below:\n",
        "\n",
        "![grafo_ejemplo.png](data:image/png;base64,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)\n",
        "\n",
        "the degree distribution is $P(0) = 1/10$, $P(1) = 2/10$, $P(2) = 4/10$, $P(3) = 2/10$, $P(4) = 1/10$ and $P(d) = 0$ for all $d>4$. From the example it should be clear that for graphs with a finite number of vertices, then the degree distribution must satisfy $P(d)=0$ for all degrees exceeding some maximum value.\n",
        "\n",
        "Note that the degree distirbution can be obtained as the normalized histogram constructed from the graph's degree sequence, using histogram *bins* of size one that are centered on the non-negative integers. "
      ],
      "metadata": {
        "id": "XHV0WQzYwqY0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Write a function that computes the degree distribution of a graph given its degree sequence. The function [`numpy.histogram`](https://numpy.org/doc/stable/reference/generated/numpy.histogram.html) may be useful to that end. A list of nodal degrees should be sufficient as input to the method, it does not need to be ordered as in the definition of degree sequence used in class.  "
      ],
      "metadata": {
        "id": "hNeWIkUY3iEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def degree_distribution(degree_sequence):\n",
        "  # TODO: Implement this function that takes the graph's degree sequence as input\n",
        "  # and returns its degree distribution\n",
        "\n",
        "  ############# your code here #############\n",
        "  \n",
        "  maxN = np.max(degree_sequence)\n",
        "  binS = np.linspace(-0.5,maxN+0.5,num=maxN+2) # create bins\n",
        "\n",
        "  degree_distribution = np.histogram(degree_sequence,binS)\n",
        "\n",
        "  degree_distribution = degree_distribution[0].tolist()\n",
        "  degree_distribution = degree_distribution/np.sum(degree_distribution)\n",
        "\n",
        "  #########################################\n",
        "\n",
        "  return degree_distribution"
      ],
      "metadata": {
        "id": "yJ4gI3-r3vp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's test that the function gives the right answer for the toy graph above\n",
        "# build the graph from the edge list\n",
        "G = nx.Graph()\n",
        "nodelist = np.arange(1,11)\n",
        "G.add_nodes_from(nodelist)\n",
        "edgelist = [(1,2), (1,3), (2,3), (3,4), (3,6), (6,7), (6,8), (8,9), (8,10), (9,10)]\n",
        "G.add_edges_from(edgelist)\n",
        "\n",
        "# fix the vertex positions\n",
        "dx = 0.5\n",
        "dy = 0.5\n",
        "pos = {1:(0,0),2:(dx,-dy),3:(2*dx,0),4:(dx,dx),5:(3*dx,dy),6:(4*dx,0),7:(3*dx,-dy),8:(5*dx,dy),9:(5*dx,-dy),10:(6*dx,0)}\n",
        "# draw the graph\n",
        "plt.figure()\n",
        "plt.title('Graph from the example')\n",
        "nx.draw_networkx(G,pos=pos,with_labels=False,node_size=100)\n",
        "\n",
        "# compile the degree sequence\n",
        "degree_list = [deg for (node,deg) in G.degree()]\n",
        "degree_dist = degree_distribution(degree_list)\n",
        "print(f'The degree distribution of the toy graph is {degree_dist}')"
      ],
      "metadata": {
        "id": "Z4CuUqXQ5DSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Power-law distributions and scale-free networks\n",
        "We say that a degree distribution obeys a *power law* if $P(d) = Cd^{-\\alpha}$. In practice, the degree distribution of several real-world networks across various domains follows a power law. In this part of the laboratory, we will work with a network of citations among machine learning papers. Data come from the paper [Automating the Construction of Internet Portals with Machine Learning](https://link.springer.com/article/10.1023/A:1009953814988). We will consider an undirected version of the graph, where vertices correspond to papers and if paper $i$ cites paper $j$ (or viceversa), then there is an edge joining $i$ and $j$. Each vertex in this graph is assigned to one of seven classes according to the paper's topic. In other words, nodes are labeled. "
      ],
      "metadata": {
        "id": "KcMYQsWwC3PN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the dataset, which is conveniently included in PyG\n",
        "from torch_geometric.datasets import Planetoid\n",
        "\n",
        "cora_dataset = Planetoid(root='/tmp/cora', name='Cora')"
      ],
      "metadata": {
        "id": "C8Q4j_-pwula"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# some dataset characteristics\n",
        "print(f'Dataset: {cora_dataset}:')\n",
        "print('======================')\n",
        "print(f'Number of graphs: {len(cora_dataset)}')\n",
        "print(f'Number of classes: {cora_dataset.num_classes}')"
      ],
      "metadata": {
        "id": "MV6aH30sw0qi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's focus on the first graph\n",
        "cora_data = cora_dataset[0]\n",
        "\n",
        "print(cora_data)\n",
        "print('==============================================================')\n",
        "\n",
        "# some descritptive graph characteristics\n",
        "print(f'Number of nodes: {cora_data.num_nodes}')\n",
        "print(f'Number of edges: {cora_data.num_edges}')\n",
        "print(f'Average node degree: {(2*cora_data.num_edges) / cora_data.num_nodes:.2f}')\n",
        "print(f'Graph has isolated nodes: {cora_data.has_isolated_nodes()}')\n",
        "print(f'Graph has self loops: {cora_data.has_self_loops()}')\n",
        "print(f'Graph is undirected: {cora_data.is_undirected()}')"
      ],
      "metadata": {
        "id": "JCbdXckJ0s74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the graph\n",
        "from torch_geometric.utils import to_networkx\n",
        "\n",
        "G_cora = to_networkx(cora_data)\n",
        "plt.figure(figsize=(12,12))\n",
        "cora_pos = nx.spring_layout(G_cora, seed=20)\n",
        "nx.draw_networkx(G_cora,node_color=cora_data.y,pos=cora_pos,with_labels=False)"
      ],
      "metadata": {
        "id": "2pEmubOQw3Ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal of this part is to assess whether the degree distribution of the citation network follows a power law. To that end, notice that a logarithmic transformation applied to both sides of the equality $P(d) = Cd^{-\\alpha}$ yields $\\log P(d) = -\\alpha \\log d + \\tilde{C}$. Accordinlgy, if a power-law degree distribution is tenable then we expect to see a linear relationship between $P(d)$ and $d$ when *plotted in log-log scale*.\n",
        "\n",
        "2. Plot the degree distribution $P(d)$ versus $d$ in log-log scale. Would you say the degree distribution obeys a power law? Discuss."
      ],
      "metadata": {
        "id": "9TvS8vKpGi_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the degree distribution for the citation network \n",
        "deg_sequence = np.array([deg for (node, deg) in G_cora.degree()])\n",
        "\n",
        "deg_distribution = degree_distribution(deg_sequence)\n",
        "\n",
        "# TODO: plot the degree distribution P(d) versus d in log-log scale\n",
        "\n",
        "############# your code here #############\n",
        "  \n",
        "plt.figure(figsize=(9,7))\n",
        "plt.title('CORA Dataset, Degree Distribution', fontsize=20)\n",
        "plt.xlabel('d', fontsize=16)\n",
        "plt.ylabel('P(d))', fontsize=16)\n",
        "\n",
        "plt.plot(np.arange(np.size(deg_distribution)),deg_distribution.transpose())\n",
        "plt.yscale('log')\n",
        "plt.xscale('log')\n",
        "plt.grid(True)\n",
        "\n",
        "#########################################"
      ],
      "metadata": {
        "id": "cq7YtyOCFFUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation of the result\n",
        "It is hard to assess the linearity of the distribution with the binning we made. When we move from low d to high d, we encounter exponentially more bins in equal distance, since we are in log-scale. This makes it harder to interpret high d bins since they are naturally more rare and noisy. However, the middle part of the distribution, between (5, 50), seem to obey power law."
      ],
      "metadata": {
        "id": "PgX2YFVkQy8v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In practice, it is rarely the case that power-law degree distributions are followed over the entire range of degrees. What typically happens instead is that we observe a good fit for large values of $d$, namely in the tail of the distribution. So in general, when we say degrees in a network obey a power-law distribution, we mean the property holds over some suitable range of the entire support. As discussed in class, said networks are often dubbed *scale-free*.\n",
        "\n",
        "In your plot of the citation network's degree distribution you should see large fluctuations for high degree values, which could hinder our ability to asses whether a power law is tenable here. The reason for this *tail noise* is that for large values of $d$, there are very few nodes with said degrees. Hence, each of the corresponding histogram bins will accrue very limited counts, explaining the high-degree fluctuations you observe. One possible workaround would be to widen the bins in the tail of the histogram so that each of them collects more samples. However, uniformly increasing the bin widths over the whole support will sacrifice the resolution of the histogram for small degree values. A good solution is thus to employ bins that are *equispaced in logarithmic scale*, an approach known as logarithmic binning.\n",
        "\n",
        "\n",
        "3. Plot a histogram for the degrees of the citation network using bins of width $2^n$, for $n=0,1,2, \\dots$ (that is, equispaced in logarithmic scale). Do you still stand by your answer to Question 2.? ¿Sigue manteniendo la misma respuesta que en la parte 2.? Are you more certain now as to whether the citation network can be characterized as scale-free?"
      ],
      "metadata": {
        "id": "ZBsx7dxjNP3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: plot a histogram for the degrees of the citation network using\n",
        "# using logarithmic binning\n",
        "\n",
        "############# your code here #############\n",
        "\n",
        "def degree_distribution_binOpt(degree_sequence,binning):\n",
        "  # TODO: Implement this function that takes the graph's degree sequence as input\n",
        "  # and returns its degree distribution\n",
        "  \n",
        "  if binning == 'log':\n",
        "    maxN = np.ceil(np.log2(np.max(degree_sequence)))\n",
        "    binS = 2**(np.linspace(-1, maxN, num=int(maxN+2))+0.1)\n",
        "  elif binning == 'linear':\n",
        "    maxN = np.max(degree_sequence)\n",
        "    binS = np.linspace(-0.5,maxN+0.5,num=maxN+2) # no given binning, assign linear binning\n",
        "  else:\n",
        "    print('Invalid binning option. Binning can be either \"log\" or \"linear\".')\n",
        "    return\n",
        "\n",
        "  degree_distribution = np.histogram(degree_sequence,binS)\n",
        "\n",
        "  degree_distribution = degree_distribution[0].tolist()\n",
        "  degree_distribution = degree_distribution #/np.sum(degree_distribution)\n",
        "\n",
        "  return degree_distribution, binS\n",
        "\n",
        "deg_distribution, bin_val = degree_distribution_binOpt(deg_sequence,'log')\n",
        "  \n",
        "plt.figure(figsize=(9,7))\n",
        "plt.title('CORA Dataset, Degree Distribution (log-log)', fontsize=20)\n",
        "plt.xlabel('d', fontsize=16)\n",
        "plt.ylabel('P(d))', fontsize=16)\n",
        "\n",
        "plt.plot(bin_val[0:-1]*(2**(1/2)),deg_distribution)\n",
        "plt.yscale('log')\n",
        "plt.xscale('log')\n",
        "plt.grid(True)\n",
        "\n",
        "#########################################"
      ],
      "metadata": {
        "id": "YpfySSfTPqNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation of the resulting figure\n",
        "Changing bin size made it clear that the tail region of the distribution also behaving linearly in the log-log scale. Distribution obeys power law. "
      ],
      "metadata": {
        "id": "oMN_4tflyTfs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pareto distribution and estimation of the power-law exponent $\\alpha$\n",
        "With the aforementioned histogram construction you should observe a degree distribution that appears to follow a power law, at least for degree values exceeding some lower bound $d_\\text{min}$. To characterize this behaviour and carry out statistical inference, we will model the observed degrees using the [Pareto distribution](https://en.wikipedia.org/wiki/Pareto_distribution). A continuous random variable $D$ has the Pareto distribution if its probability density function (pdf) is given by:\n",
        "\n",
        "$$p(d) = \\left\\lbrace \\begin{array}{c c} C d^{-\\alpha} & \\text{ if } d\\geq d_\\text{min} \\\\ 0 & \\text{ otherwise} \\end{array}\\right.$$\n",
        "\n",
        "4. Determine the value of the constant $C$ so that $p(d)$ is a valid pdf.\n",
        "\n",
        "Consider now the important statistical inference task of estimating the power-law exponent $\\alpha$. Given $n$ independent and identically distributed (i.i.d.) degree observations $d_1,\\dots,d_{n}$ from a Pareto distribution, it is not hard to show (see the optional exercise at the end of the laboratory) that the maximum-likelihood estimator (MLE) of $\\alpha$ is given by:\n",
        "\n",
        "$$\\hat{\\alpha} = 1 +  \\left[\\frac{1}{n}\\sum_{i=1}^{n} \\log \\left(\\frac{d_i}{d_\\text{min}}\\right)\\right]^{-1}.$$\n",
        "\n",
        "5. Write a function that implements the aforementioned MLE, given the degree sequence and $d_{\\min}$ as inputs. Estimate the power-law exponent for the citation network."
      ],
      "metadata": {
        "id": "nim7AxeAjaK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def alpha_maximum_likelihood(deg_sequence, d_min):\n",
        "  # TODO: Implement this function that takes the graph's degree sequence and \n",
        "  # the degree lower bound (from which a power law is credible) as inputs, and\n",
        "  # returns the MLE of α\n",
        "\n",
        "  # alpha always greater than 1, for pdf to be normalizable\n",
        "  # alpha_hat = 0\n",
        "\n",
        "  ############# your code here #############\n",
        "\n",
        "  deg_distribution, bin_val = degree_distribution_binOpt(deg_sequence,'log')\n",
        "\n",
        "  log_bin_centers = (bin_val[:-1] + bin_val[1:]) / 2\n",
        "\n",
        "  deg_distribution = np.asarray(deg_distribution)\n",
        "  deg_distribution = deg_distribution[log_bin_centers > d_min]\n",
        "  n = np.size(deg_distribution)\n",
        "  log_weighted_degree = np.sum(np.log(deg_distribution/d_min))\n",
        "  alpha_hat = 1 + n / log_weighted_degree\n",
        "  \n",
        "  #########################################\n",
        "\n",
        "  return alpha_hat\n",
        "\n"
      ],
      "metadata": {
        "id": "LR9N1eycQmxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's compute $\\hat{\\alpha}$ for the citation network. If your implementation of the MLE is correct, then you should obtain a value that is around $4$."
      ],
      "metadata": {
        "id": "Kugh-rpKSfYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d_min = 10\n",
        "alpha_hat_cora = alpha_maximum_likelihood(deg_sequence, d_min)\n",
        "\n",
        "print(f\"The estimated value of α for the paper citation network is {alpha_hat_cora:.3f}\" )"
      ],
      "metadata": {
        "id": "UXtw2txo2eEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Assortative mixing and the modularity coefficient\n",
        "\n",
        "In social networks, the notion of [*homophily*](https://en.wikipedia.org/wiki/Homophily) refers to the tendency of actors in the network towards selectively establishing ties with other actors that are similar in some context-dependent sense (i.e., \"birds of a feather flock together\"). In Network Science lingo, this tendency is often dubbed *assortative mixing*.\n",
        "\n",
        "When vertices are labeled with categorical attributes or classes, a natural measure of assortativity is to quantify the fraction of edges in the network joining vertices in the same class. To fix ideas, suppose that each vertex belongs to one of $N_c$ classes (that is, each vertex $i$ has an attribute or label $c_i\\in \\{1,\\dots,N_c\\}$ indicating its membership to one of the $N_c$ classes). A metric to quantify the level of homophily or assortativity in a network is known as *modularity*, and is defined as:\n",
        "\n",
        "$$Q = \\frac{1}{2N_E} \\sum_{i,j\\in V} \\left(A_{ij} -\\frac{d_id_j}{2N_E} \\right)\\delta(c_i,c_j),$$\n",
        "\n",
        "where $N_E$ is the number of edges in the graph, $A_{ij}$ denotes the $(i,j)$th entry of the adjacency matrix, $d_i$ is the degree of vertix $i$, and $\\delta(r,p)$ stands for the Kronecker delta: $\\delta(r,p) = 1$ if $r=p$ and $\\delta(r,p) = 0$ if $r\\neq p$. The modularity coefficient $Q$ compares the fraction of edges in the observed graph that join vertices from the same class against what would be obtained if the edges where assigned at random (while preserving the degree distribution of the original graph). The modularity coefficient $Q$ is strictly less than 1, it takes on positive values if edges predominantly join vertices of the same class, and negative values otherwise.\n",
        "\n",
        "In this part of the laboratory we will compute the modularity coefficient for the citation network as well as for another network graph constructed from commercial airline flights within the US."
      ],
      "metadata": {
        "id": "Yxxmr-YoGwXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# same as usual, import the dataset from PyG\n",
        "from torch_geometric.datasets import Airports\n",
        "\n",
        "airports_dataset = Airports(root='/tmp/airports', name='USA')"
      ],
      "metadata": {
        "id": "zpqFxapVFT9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# some dataset characteristics\n",
        "print(f'Dataset: {airports_dataset}:')\n",
        "print('======================')\n",
        "print(f'Number of graphs: {len(airports_dataset)}')\n",
        "print(f'Number of classes: {airports_dataset.num_classes}')"
      ],
      "metadata": {
        "id": "KtyB3KNoFZIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's focus on the first graph\n",
        "airports_data = airports_dataset[0]\n",
        "\n",
        "print(airports_data)\n",
        "print('==============================================================')\n",
        "\n",
        "# some descritptive graph characteristics\n",
        "print(f'Number of nodes: {airports_data.num_nodes}')\n",
        "print(f'Number of edges: {airports_data.num_edges}')\n",
        "print(f'Average node degree: {(2*airports_data.num_edges) / airports_data.num_nodes:.2f}')\n",
        "print(f'Graph has isolated nodes: {airports_data.has_isolated_nodes()}')\n",
        "print(f'Graph has self loops: {airports_data.has_self_loops()}')\n",
        "print(f'Graph is undirected: {airports_data.is_undirected()}')"
      ],
      "metadata": {
        "id": "qRz03nckFoHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fb5EFfE16GcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flight data used to construct the graph come from the paper [struc2vec: Learning Node Representations from Structural Identity](https://arxiv.org/pdf/1704.03165.pdf). Vertices correspond to US airports, an arc joining airports $i$ and $j$ indicates the existence of a commercial flight traveling from $i$ to $j$ (the resulting graph is directed). Each airport has an attribute indicating their level of activity, measured as the total number of passengers served by the airport over the data collection horizon (January to October, 2016). To obtain catergorical node attributes (or class labels), airports were assigned to $4$ classes according to the quartiles of the empirical activity distribution. Namely, class 0 corresponds to 25% of the airports with least activity, and so forth."
      ],
      "metadata": {
        "id": "-NlyvRN0F8Tr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the graph\n",
        "G_airports = to_networkx(airports_data)\n",
        "plt.figure(figsize=(12,12))\n",
        "airports_pos = nx.spring_layout(G_airports, seed=20)\n",
        "nx.draw_networkx(G_airports,node_color=airports_data.y,pos=airports_pos,with_labels=False)"
      ],
      "metadata": {
        "id": "m11JPyV9IYDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Compute the modularity coefficient for the airport and paper citation networks. You may find the function[`networkx.algorithms.community.modularity`](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.community.quality.modularity.html) handy, in addition to the function `communities_partition` provided below.\n",
        "7. What do the respective values tell you about the structure of relational ties established in each of the networks? Do these align with your prior intuitions given the nature and structure of these complex systems?"
      ],
      "metadata": {
        "id": "_p3cEYwaH_vY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def communities_partition(labels):\n",
        "  # Function that, given a list of class membership labels for each vertex \n",
        "  # in a graph, returns a partition of the graph in those communities (classes). \n",
        "\n",
        "  # let's check how many different communities there are\n",
        "  communities_labels = np.unique(labels)\n",
        "\n",
        "  # partition the graph. See the example in https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.community.quality.modularity.html\n",
        "  # to understand the format of this function's output\n",
        "\n",
        "  partition = [set(np.where(labels == community_idx)[0]) for community_idx in communities_labels]\n",
        "\n",
        "  return partition"
      ],
      "metadata": {
        "id": "Bw2oFh2IbEyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6"
      ],
      "metadata": {
        "id": "BM1KAZqUYN1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: compute the modularity coefficient for the airport and paper citation networks\n",
        "\n",
        "############# your code here #############\n",
        "\n",
        "labels_airports = airports_data.y\n",
        "partition_airports = communities_partition(labels_airports)\n",
        "Q_airports = nx.algorithms.community.modularity(G_airports,partition_airports)\n",
        "print(f\"Modularity for the airport network, labeled according to their activity, is {Q_airports: .3f}\")\n",
        "\n",
        "labels_cora = cora_data.y\n",
        "partition_cora = communities_partition(labels_cora)\n",
        "Q_cora = nx.algorithms.community.modularity(G_cora,partition_cora)\n",
        "print(f\"Modularity for the citation network, labeled according to their topics, is {Q_cora: .3f}\")\n",
        "\n",
        "#########################################"
      ],
      "metadata": {
        "id": "fta4FRuxLHOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7 \n",
        "Citation network returned a positive Q value that is close to one, whereas airport network returned a positive value that is very close to zero. The modularity value that citation network has implies the strong homophilic nature of the interactions within the network. On the other hand, modularity value of the airport network shows the insignificance of the homophily explaining the nature of the airport network, since it is close to zero. \n",
        "\n",
        "This is an expected result for the networks at hand. It is rare to master two different topic and cite both literature equivalently. Naturally one has tendencies, or bias to cite the literature they is contributing to. It explains the high positive Q value we get for the citation network. The way the airport network was labeled is quite different than it is for citation network. First, airport are classified according to how much they contribute to the overall traffic, activity. If activity in the airport network assumed to be random with the same level of activity for each node, it is normal to have more interaction between the active airports. But the probability of having connection drops down with the decreasing total activity of the two nodes we are inspecting. For example, it is less likely to observe a connection between a less active airport and highly active airport. This trend does not change if we lower the total activity again. It is least probable to observe a connection between two airport with low activity, which nullifies the contribution coming from the interaction between the highly active airports. In this way randomness explains the small absolute value of the modularity of the airport network. Second, the classification divided the network into four equally populous category. In this way, the top 25 percent of the airports will hold the huge chunk of the activity and make a huge positive contribution to the modularity. However it is not necessarily the best way of doing the labeling. We may observe a lower modularity if we categorize the airports according to the activity portion they contributes. For example, total activity of the first group sums up to 25 percent of the total activity and so on. With this last caveat, the modularity we calculated is an expected result for the labeling made for each network."
      ],
      "metadata": {
        "id": "3mVICyilYQrK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Community detection\n",
        "In this section we will implement a couple algorithms we saw in class to partition a graph into two communities: *spectral graph partitioning* and *spectral modularity maximization*. As their name suggests, both are methods that rely on the spectral decomposition (i.e., in terms of eigenvalues and eigenvectors) of a judicious graph-dependent matrix. We will first test both algorithms on the most famous of community detection benchmarks: Zachary's karate club (check also the history of [Zachary's Karate Club Club prize recepients](https://networkkarate.tumblr.com/); looking forward to seeing you recognized in the near future).\n"
      ],
      "metadata": {
        "id": "y0HbTfctG3ej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the karate club version from NetworkX, where nodes are labeled as in Zachary's\n",
        "# original paper (in two communities, recall PyG's version splits nodes into four\n",
        "# classes)\n",
        "G_karate = nx.karate_club_graph()\n",
        "\n",
        "# each node has an attribute 'club' indicating community membership\n",
        "communities_gt = [G_karate.nodes[node]['club'] for node in G_karate.nodes()]\n",
        "print(f\"Zachary's karate club communities: {np.unique(communities_gt)}\")"
      ],
      "metadata": {
        "id": "7AFyjVxHS25B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Networkx labels communities with strings ('Mr. Hi' and 'Officer'). Let's encode\n",
        "# them using two arbitrary integers\n",
        "communities_dict = {'Mr. Hi': -1, 'Officer':1}\n",
        "communities_gt_int = [communities_dict[gt] for gt in communities_gt]\n",
        "\n",
        "# visualize the graph with color-coded communities\n",
        "plt.figure(figsize=(8,8))\n",
        "karate_pos = nx.spring_layout(G_karate, seed=42)\n",
        "nx.draw_networkx(G_karate,node_color=communities_gt_int,pos=karate_pos,cmap='coolwarm')"
      ],
      "metadata": {
        "id": "Cteya_-lUhro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Spectral graph partitioning\n",
        "The graph (bi)*partitioning* problem is to divide the graph into two communities (in other words, to cluster the vertices into two non-overlapping groups) whose size is fixed a priori. The *network community detection* problem is one in which we do not prescribe the number of vertices in each community. More precisely, in community detection we do not specify the number of communities either; but we will henceforth stick with the formulation where we assume we want to find two groups of vertices. As its name suggests, the *spectral graph partitioning* algorithms falls under the first category. "
      ],
      "metadata": {
        "id": "tMSGGyBikcnX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Implement the spectral graph partitioning algorithm we discussed in class. Your function should partition the vertex set of a given graph $G$ into two groups of given cardinalities $n_1$ and $n_2$, such that the graph cut is (approximately) minimized. "
      ],
      "metadata": {
        "id": "XG7--6WIV3u1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse.linalg import eigsh\n",
        "\n",
        "def spectral_partitioning(G,n_1,n_2):\n",
        "  # TODO: Implement the spectral graph partitioning algorithm. This function\n",
        "  # takes as input a graph G in NetworkX format and two integers n_1 and n_2\n",
        "  # (given community sizes). It returns a numpy vector with class assignments \n",
        "  # for each vertex, coded using two different integers of your choice.\n",
        "\n",
        "  communities_assignments = np.zeros((G.number_of_nodes(),))\n",
        "\n",
        "  ############# your code here #############\n",
        "\n",
        "  A = nx.adjacency_matrix(G).toarray()\n",
        "  D = np.diag(np.sum(A, axis=1))\n",
        "  L = D - A\n",
        "  L_norm = np.linalg.inv(np.sqrt(D)) @ L @ np.linalg.inv(np.sqrt(D))\n",
        "  \n",
        "  # Compute the second smallest eigenvector of L_norm\n",
        "  _, V = eigsh(L_norm, k=2, which='SA')\n",
        "  V_2 = V[:,1]\n",
        "\n",
        "  # sort from largest to smallest\n",
        "  sorted_indices = np.argsort(V_2)[::-1] \n",
        "\n",
        "  # make community assignments\n",
        "  communities_assignments[sorted_indices[:n_1]] = 0\n",
        "  communities_assignments[sorted_indices[n_1:]] = 1\n",
        "\n",
        "  #########################################\n",
        "\n",
        "  return communities_assignments"
      ],
      "metadata": {
        "id": "vX7HiLpLG_W2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If your algorithm is working correctly, it should perfectly recover the class assignments when you partition the network into equal-sized communities (i.e., $n_1=n_2$)."
      ],
      "metadata": {
        "id": "yPrs5nK1aTK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# partition into equal-sized communities (graph bisection)\n",
        "n_1 = int(G_karate.number_of_nodes()/2)\n",
        "n_2 = n_1\n",
        "karate_partition = spectral_partitioning(G_karate,n_1,n_2)\n",
        "\n",
        "# remap labels so that they match the order in the ground truth ones\n",
        "karate_partition = remap_labels(communities_gt_int,karate_partition)\n",
        "\n",
        "# visualize the graph indicating the estimated community assignments\n",
        "plt.figure(figsize=(16,8))\n",
        "ax1 = plt.subplot(1,2,1)\n",
        "_= ax1.set_title('Ground-truth labels',fontsize = 16)\n",
        "nx.draw_networkx(G_karate,node_color=communities_gt_int,pos=karate_pos,ax=ax1,cmap='coolwarm')\n",
        "ax2 = plt.subplot(1,2,2)\n",
        "nx.draw_networkx(G_karate,node_color=karate_partition,pos=karate_pos,ax=ax2,cmap='coolwarm')\n",
        "_= ax2.set_title('Estimated labels',fontsize = 16)"
      ],
      "metadata": {
        "id": "ltYqRfcFXzEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A standard metric to evaluate the performance of a graph partitioning (or a generic clustering) algorithm is via the [Rand index](https://en.wikipedia.org/wiki/Rand_index). The Rand index takes values between $0$ and $1$, while higher is better. A value of $1$ is attained when the algorithm returns an assignment identical to the ground truth. The adjusted Rand index is the corrected-for-chance version of the Rand index."
      ],
      "metadata": {
        "id": "tBRAwghObuJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import adjusted_rand_score\n",
        "# we use the adjusted_rand_score, defined in such a way that for random community\n",
        "# assignments we are likely to get scores that are close to 0 (this may not hold\n",
        "# for the vanilla Rand index)\n",
        "rand_score_spectral = adjusted_rand_score(communities_gt_int,karate_partition)\n",
        "print(f\"Adjusted Rand index for our partitioning of the karate club: {rand_score_spectral:.3f}\")"
      ],
      "metadata": {
        "id": "v6dx35OXaw7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another useful metric to evaluate clustering performance is the [Fowlkes-Mallows index](https://scikit-learn.org/stable/modules/clustering.html#fowlkes-mallows-scores) (a.k.a. F-score), defined as the geometric mean between [precision and recall](https://en.wikipedia.org/wiki/Precision_and_recall) of the assignment. Once more, the F-score ranges from 0 to 1 and the highest value corresponds to a perfect assignment."
      ],
      "metadata": {
        "id": "3TpvAynUdwLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import fowlkes_mallows_score\n",
        "# nicely enough, sklearn has implementations of these indices (and several others);\n",
        "# see https://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation\n",
        "mallows_score_spectral = fowlkes_mallows_score(communities_gt_int,karate_partition)\n",
        "print(f\"Fowlkes-Mallows index for our partitioning of the karate club: {mallows_score_spectral:.3f}\")"
      ],
      "metadata": {
        "id": "zV56YOwhdSsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see what we obtain if we make random community membership assignments."
      ],
      "metadata": {
        "id": "P-f5RRyhf7QR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# randomly assign labels\n",
        "random_assignments = np.random.randint(1,size=G_karate.number_of_nodes())\n",
        "\n",
        "rand_score_random = adjusted_rand_score(communities_gt_int,random_assignments)\n",
        "mallows_score_random = fowlkes_mallows_score(communities_gt_int,random_assignments)\n",
        "print(f\"Adjusted Rand index for random assignments in the karate club: {rand_score_random:.3f}\")\n",
        "print(f\"Fowlkes-Mallows index for random assignments in the karate club: {mallows_score_random:.3f}\")"
      ],
      "metadata": {
        "id": "8KAveronfGJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Spectral modularity maximization\n",
        "A potential limitation of the spectral graph partitioning method we implemented is that we need to prescribe the number of vertices in each community (by the way, there are workarounds as we saw in class; say by minimizing the ratio cut). Alternatively, *spectral modularity maximization* is another approach to detect two communities without knowing their respective sizes. For all of these methods, there are variations to detect more than two communities that we will not be exploring here."
      ],
      "metadata": {
        "id": "CRkWpXc8kgKJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Implement the spectral modularity maximization algorithm we discussed in class. Your function should partition the vertex set of a given graph $G$ into two groups, such that the modularity of the partition is (approximately) maximized. The function [`networkx.modularity_matrix`](https://networkx.org/documentation/stable/reference/generated/networkx.linalg.modularitymatrix.modularity_matrix.html) may be handy to this end."
      ],
      "metadata": {
        "id": "ioPfcHB_hjPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def spectral_modularity_maximization(G):\n",
        "  # TODO: Implement the spectral modularity maximization algorithm. This function\n",
        "  # takes as input a graph G in NetworkX format. It returns a numpy vector with \n",
        "  # class assignments for each vertex, coded using two different integers of \n",
        "  # your choice.\n",
        "  \n",
        "  communities_assignments = np.zeros((G.number_of_nodes(),1))\n",
        "  ############# your code here #############\n",
        "  \n",
        "  # Compute the modularity matrix\n",
        "  A = nx.adjacency_matrix(G).todense()\n",
        "  D = np.sum(A, axis=0)\n",
        "  m = D.sum()\n",
        "  B = A - np.outer(D, D) / m\n",
        "\n",
        "  # Compute the dominant eigenvector of B using the power method\n",
        "  n = B.shape[0]\n",
        "  epsilon = 1e-8 \n",
        "  max_iterations = 1000\n",
        "  x = np.random.rand(n) # initiate eigenvector\n",
        "  x = x / np.linalg.norm(x) # normalize\n",
        "  x = x.reshape(n, 1)\n",
        "  lambda_B = 0 # initiate eigenvalue\n",
        "    \n",
        "  # Iterate until convergence or maximum number of iterations is reached\n",
        "  for i in range(max_iterations):\n",
        "      # Multiply A by the eigenvector\n",
        "      Bx = B @ x\n",
        "      # Calculate the new eigenvalue\n",
        "      lambda_B_new = np.dot(Bx.T, x)\n",
        "        \n",
        "      # Check if the new eigenvalue is close to the previous one\n",
        "      if np.abs(lambda_B_new - lambda_B) < epsilon:\n",
        "          break\n",
        "        \n",
        "      # Update the eigenvalue and eigenvector\n",
        "      lambda_B = lambda_B_new\n",
        "      x = Bx / np.linalg.norm(Bx)\n",
        "\n",
        "  # Make community assignments using the signs of the elements of the dominant eigenvector\n",
        "  sign_x = np.squeeze(np.sign(x)).T\n",
        "  communities_assignments[sign_x==1] = 0\n",
        "  communities_assignments[sign_x==-1] = 1\n",
        "\n",
        "  #########################################\n",
        "\n",
        "  return communities_assignments"
      ],
      "metadata": {
        "id": "LubOAKo5h99B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case, the algorithm should correctly label all vertices except one of them (node number 8). This can be viewed as the price paid for not knowing the true community sizes a priori."
      ],
      "metadata": {
        "id": "qgi2MjD6jFnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "karate_modularity_assingments = spectral_modularity_maximization(G_karate)\n",
        "\n",
        "# remap labels so that they match the order in the ground truth ones\n",
        "karate_modularity_assingments = remap_labels(communities_gt_int,karate_modularity_assingments)\n",
        "\n",
        "# visualize the graph indicating the estimated community assignments.\n",
        "# vertex 8 belongs to the community depicted below, but the estimated label should\n",
        "# place it as a member of the community depicted above\n",
        "plt.figure(figsize=(16,8))\n",
        "ax1 = plt.subplot(1,2,1)\n",
        "_= ax1.set_title('Ground-truth labels',fontsize = 16)\n",
        "nx.draw_networkx(G_karate,node_color=communities_gt_int,pos=karate_pos,ax=ax1,cmap='coolwarm')\n",
        "ax2 = plt.subplot(1,2,2)\n",
        "nx.draw_networkx(G_karate,node_color=karate_modularity_assingments,pos=karate_pos,ax=ax2,cmap='coolwarm')\n",
        "_= ax2.set_title('Estimated labels',fontsize = 16)\n",
        "\n",
        "# compute scores to assess clustering quality\n",
        "rand_score_modularity = adjusted_rand_score(communities_gt_int,karate_modularity_assingments)\n",
        "mallows_score_modularity = fowlkes_mallows_score(communities_gt_int,karate_modularity_assingments)\n",
        "print(f\"Adjusted Rand index for our modularity-based clustering of the karate club: {rand_score_modularity:.3f}\")\n",
        "print(f\"Fowlkes-Mallows index for our modularity-based clustering of the karate club: {mallows_score_modularity:.3f}\")"
      ],
      "metadata": {
        "id": "UsOyY9-Akjnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Partitioning a network of US political blogs\n",
        "To conclude, we will study a network of Internet blogs on the subject of US politics, with the goal of partitioning the graph into liberal (i.e., Democrat) and conservative (i.e., Republican) `blogger communities’. Data on the 2004 US Election’s political blogosphere was compiled by L. Adamic and N. Glance in 2005; see also their paper [The Political Blogosphere and the 2004 US Election: Divided they Blog](https://dl.acm.org/doi/10.1145/1134271.1134277).\n",
        "\n",
        "Here we use an undirected version of the original directed graph, where edges correspond to hyperlinks between blogs. The network comprises $N_v=1490$\n",
        "blogs (vertices), and a binary attribute associated to each vertex indicates political leaning according to: 0 (liberal) and 1 (conservative)."
      ],
      "metadata": {
        "id": "FCA64xK7zzml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# in November'22 the PolBlogs dataset changed format to .tsv files instead of\n",
        "# .csv. Hence, loading PolBlogs from PyG gives an error. Copying the PolBlogs \n",
        "# code here and modifying it so that it works \n",
        "\n",
        "import os\n",
        "from typing import Callable, List, Optional\n",
        "from torch_geometric.data import (\n",
        "    Data,\n",
        "    InMemoryDataset,\n",
        "    download_url,\n",
        "    extract_tar,\n",
        ")\n",
        "\n",
        "class PolBlogs(InMemoryDataset):\n",
        "    r\"\"\"The Political Blogs dataset from the `\"The Political Blogosphere and\n",
        "    the 2004 US Election: Divided they Blog\"\n",
        "    <https://dl.acm.org/doi/10.1145/1134271.1134277>`_ paper.\n",
        "\n",
        "    :class:`Polblogs` is a graph with 1,490 vertices (representing political\n",
        "    blogs) and 19,025 edges (links between blogs).\n",
        "    The links are automatically extracted from a crawl of the front page of the\n",
        "    blog.\n",
        "    Each vertex receives a label indicating the political leaning of the blog:\n",
        "    liberal or conservative.\n",
        "\n",
        "    Args:\n",
        "        root (str): Root directory where the dataset should be saved.\n",
        "        transform (callable, optional): A function/transform that takes in an\n",
        "            :obj:`torch_geometric.data.Data` object and returns a transformed\n",
        "            version. The data object will be transformed before every access.\n",
        "            (default: :obj:`None`)\n",
        "        pre_transform (callable, optional): A function/transform that takes in\n",
        "            an :obj:`torch_geometric.data.Data` object and returns a\n",
        "            transformed version. The data object will be transformed before\n",
        "            being saved to disk. (default: :obj:`None`)\n",
        "\n",
        "    **STATS:**\n",
        "\n",
        "    .. list-table::\n",
        "        :widths: 10 10 10 10\n",
        "        :header-rows: 1\n",
        "\n",
        "        * - #nodes\n",
        "          - #edges\n",
        "          - #features\n",
        "          - #classes\n",
        "        * - 1,490\n",
        "          - 19,025\n",
        "          - 0\n",
        "          - 2\n",
        "    \"\"\"\n",
        "\n",
        "    url = 'https://netset.telecom-paris.fr/datasets/polblogs.tar.gz'\n",
        "\n",
        "    def __init__(self, root: str, transform: Optional[Callable] = None,\n",
        "                 pre_transform: Optional[Callable] = None):\n",
        "        super().__init__(root, transform, pre_transform)\n",
        "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self) -> List[str]:\n",
        "        return ['adjacency.tsv', 'labels.tsv']\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self) -> str:\n",
        "        return 'data.pt'\n",
        "\n",
        "    def download(self):\n",
        "        path = download_url(self.url, self.raw_dir)\n",
        "        extract_tar(path, self.raw_dir)\n",
        "        os.unlink(path)\n",
        "\n",
        "    def process(self):\n",
        "        import pandas as pd\n",
        "\n",
        "        edge_index = pd.read_csv(self.raw_paths[0], header=None, sep='\\t', usecols=[0,1])\n",
        "        edge_index = torch.from_numpy(edge_index.values).t().contiguous()\n",
        "\n",
        "        y = pd.read_csv(self.raw_paths[1], header=None, sep='\\t')\n",
        "        y = torch.from_numpy(y.values).view(-1)\n",
        "\n",
        "        data = Data(edge_index=edge_index, y=y, num_nodes=y.size(0))\n",
        "\n",
        "        if self.pre_transform is not None:\n",
        "            data = self.pre_transform(data)\n",
        "\n",
        "        torch.save(self.collate([data]), self.processed_paths[0])"
      ],
      "metadata": {
        "id": "-sar9GUh5JDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the dataset\n",
        "blogs_dataset = PolBlogs(root='/tmp/polblogs')"
      ],
      "metadata": {
        "id": "bLKtCj_hw7V3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# some dataset characteristics\n",
        "print(f'Dataset: {blogs_dataset}:')\n",
        "print('======================')\n",
        "print(f'Number of graphs: {len(blogs_dataset)}')\n",
        "print(f'Number of classes: {blogs_dataset.num_classes}')"
      ],
      "metadata": {
        "id": "UmA8O5-S0De6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's focus on the first (and only) graph\n",
        "blogs_data = blogs_dataset[0]\n",
        "\n",
        "print(blogs_data)\n",
        "print('==============================================================')\n",
        "\n",
        "# some descriptive graph characteristics\n",
        "print(f'Number of nodes: {blogs_data.num_nodes}')\n",
        "print(f'Number of edges: {blogs_data.num_edges}')\n",
        "print(f'Average node degree: {(2*blogs_data.num_edges) / blogs_data.num_nodes:.2f}')\n",
        "print(f'Graph has isolated nodes: {blogs_data.has_isolated_nodes()}')\n",
        "print(f'Graph has self loops: {blogs_data.has_self_loops()}')\n",
        "print(f'Graph is undirected: {blogs_data.is_undirected()}')"
      ],
      "metadata": {
        "id": "nF68e6uk0EHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that the graph is directed and has self loops. So we will modify the graph to make it undirected and remove all self loops. Morever, since the graph is disconnected we will perform community detection on the network's largest connected component."
      ],
      "metadata": {
        "id": "zYE4Z11Wmk5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the graph to an undirected one using NetworkX because PyG converts it\n",
        "# using only the lower (or upper) triangular part of the adjacency matrix. \n",
        "G_blogs = to_networkx(blogs_data, to_undirected=False)\n",
        "G_blogs = G_blogs.to_undirected()\n",
        "\n",
        "# only retain the largest connected component\n",
        "largest_cc_nodes = max(nx.connected_components(G_blogs), key=len)\n",
        "G_lcc = G_blogs.subgraph(largest_cc_nodes).copy()\n",
        "\n",
        "# remove all self loops\n",
        "G_lcc.remove_edges_from(nx.selfloop_edges(G_lcc))\n",
        "\n",
        "# only keep the labels from the vertices in the largest component\n",
        "G_lcc_labels = blogs_data.y[list(largest_cc_nodes)]\n",
        "\n",
        "# visualize the graph\n",
        "G_lcc_pos = nx.spring_layout(G_lcc, seed=20)\n",
        "plt.figure(figsize=(12,12))\n",
        "nx.draw_networkx(G_lcc,node_color=G_lcc_labels,pos=G_lcc_pos,with_labels=False)"
      ],
      "metadata": {
        "id": "lRPiXS3R0IkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because we do not know the sizes of the communities we are after (unless we cheat and look at the ground-truth labels), we will use the spectral modularity maximization algorithm. Note that this is a realistic setting where it is safe to say that we know the number of communities we seek to unveil."
      ],
      "metadata": {
        "id": "_83mt1YYoPI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# perform network community detection using our implementation of spectral \n",
        "# modularity maximization\n",
        "mod_max_blogs = spectral_modularity_maximization(G_lcc)\n",
        "# remap labels so that they match the order in the ground truth ones\n",
        "mod_max_blogs = remap_labels(G_lcc_labels,mod_max_blogs)\n",
        "\n",
        "# visualize the graph indicating the estimated community assignments\n",
        "plt.figure(figsize=(20,10))\n",
        "ax1 = plt.subplot(1,2,1)\n",
        "_= ax1.set_title('Ground-truth labels',fontsize = 16)\n",
        "nx.draw_networkx(G_lcc,node_color=G_lcc_labels,pos=G_lcc_pos,with_labels=False,ax=ax1)\n",
        "ax2 = plt.subplot(1,2,2)\n",
        "nx.draw_networkx(G_lcc,node_color=mod_max_blogs,pos=G_lcc_pos,with_labels=False,ax=ax2)\n",
        "_= ax2.set_title('Estimated labels using spectral modularity maximization',fontsize = 16)"
      ],
      "metadata": {
        "id": "XmRDsLFW0vUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute scores to assess the quality of the identified communities. You should get values that are close to $1$ for both metrics."
      ],
      "metadata": {
        "id": "K-hnvk-e3ZeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rand_score_blogs = adjusted_rand_score(G_lcc_labels, mod_max_blogs)\n",
        "mallows_score_blogs = fowlkes_mallows_score(G_lcc_labels,mod_max_blogs)\n",
        "print(f\"Adjusted Rand index for our modularity-based clustering of the political blogs: {rand_score_blogs:.3f}\")\n",
        "print(f\"Fowlkes-Mallows index for our modularity-based clustering of the karate club: {mallows_score_blogs:.3f}\")"
      ],
      "metadata": {
        "id": "6pBt1fdq2keN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Do you see any cualitative difference when comparing the figures above? Does this examination tell you anything about potential limitations of the spectral modularity maximization approach to network community detection?"
      ],
      "metadata": {
        "id": "o15DMdTtp6ST"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spectral modularity maximization algorithm makes classification quite succesfully according to both Rand index and Fowlkes-Mallows index. It makes classification that is significantly different than the null model and results in a relevant partition for the graph. However, between two groups elements more frequently assigned to the wrong group. Then, qualitatively spectral modularity maximization has limitation about assigning nodes that are off not well seperated region of the communities."
      ],
      "metadata": {
        "id": "39by7ug0XzVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optional excercise for extra credit: Maximum likelihood estimator of $\\alpha$ in the Pareto distribution\n",
        "\n",
        "The goal of this optional exercise is to derive the MLE for the slope parameter in the Pareto distribution (a.k.a. the Hill estimator). \n",
        "\n",
        "1. Given $n$ independent and identically distributed (i.i.d.) degree observations $d_1,\\dots,d_{n}$ from a Pareto distribution (recall the pdf expression given above). Show that the log-likelihood function is given by:\n",
        "$$\\ell_n(\\alpha) = n \\log (\\alpha -1)-n\\log d_\\text{min} - \\alpha \\sum_{i=1}^n \\log \\left(\\frac{d_i}{d_\\text{min}}\\right).$$\n",
        "\n",
        "2. Conclude that the MLE for $\\alpha$ is:\n",
        "$$\\hat{\\alpha} = 1 + n \\left[\\sum_{i=1}^n \\log \\left(\\frac{d_i}{d_\\text{min}}\\right)\\right]^{-1}.$$"
      ],
      "metadata": {
        "id": "e-3W-qoxVqWI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "07HyZ54uDNrA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}